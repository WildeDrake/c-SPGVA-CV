import argparse
import os
import random
import numpy as np
import torch
import torch.optim as optim
from model_diva import DIVA
from utils.semgdata_loader import semgdata_load, load_split


TOTAL_SUBJECTS = 12
CROSS_SUBJECT = 2
TRAIN_SUBJECTS = TOTAL_SUBJECTS - CROSS_SUBJECT
TOTAL_GESTURES = 5

# ------------------------------ Utils ------------------------------ #
# FunciÃ³n de entrenamiento por Ã©poca
def train_one_epoch(train_loader, model, optimizer, device):
    model.train()
    total_loss = 0.0
    total_class_y_loss = 0.0
    for x, y, d in train_loader:
        x, y, d = x.to(device), y.to(device), d.to(device)
        optimizer.zero_grad()
        loss, class_y_loss, *_ = model.loss_function(d, x, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        total_class_y_loss += class_y_loss.item() if hasattr(class_y_loss, 'item') else float(class_y_loss)
    n_batches = len(train_loader)
    return total_loss / n_batches, total_class_y_loss / n_batches

# FunciÃ³n para calcular accuracy
def compute_accuracy_from_logits(pred_logits, y_onehot):
    pred_labels = pred_logits.argmax(dim=1)
    true_labels = y_onehot.argmax(dim=1)
    correct = (pred_labels == true_labels).sum().item()
    return correct / float(pred_labels.size(0))

# FunciÃ³n de evaluaciÃ³n
def evaluate(loader, model, device):
    model.eval()
    acc_y, acc_d = [], []
    with torch.no_grad():
        for x, y, d in loader:
            x, y, d = x.to(device), y.to(device), d.to(device)
            pred_d, pred_y = model.classifier(x)
            acc_y.append(compute_accuracy_from_logits(pred_y, y))
            acc_d.append(compute_accuracy_from_logits(pred_d, d))
    return float(np.mean(acc_d)), float(np.mean(acc_y))


# ------------------------------ Main ------------------------------ #
def main(args):
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)
    device = torch.device("cuda" if (not args.no_cuda and torch.cuda.is_available()) else "cpu")
    kwargs = {'num_workers': 4, 'pin_memory': True} if device.type == 'cuda' else {}

    # ------------------------------ DataLoaders ------------------------------ #
    ROOT = "./preprocessed_dataset"
    train_loader = load_split(ROOT, "training", batch_size=args.batch_size)
    val_loader = load_split(ROOT, "validation", batch_size=args.batch_size)
    test_loader = load_split(ROOT, "testing", batch_size=args.batch_size)
    cross_subject_loader = load_split(ROOT, "cross_subject", batch_size=args.batch_size)
    
    # ------------------------------ Modelo y optimizador ------------------------------ #
    model = DIVA(args).to(device)
    optimizer = optim.Adam(model.parameters(), lr=args.lr)

    # ------------------------------ Early stopping ------------------------------ #
    best_y_acc = 0.0
    best_loss = float('inf')
    early_counter = 0
    model_name = os.path.join(args.outpath, f"diva_cross_subject_seed{args.seed}.model")

    # ------------------------------ Entrenamiento ------------------------------ #
    for epoch in range(1, args.epochs + 1):
        print(f"Epoch {epoch}/{args.epochs}")
        # Warm-up beta
        if args.warmup > 0 and epoch <= args.warmup:
            frac = epoch / args.warmup
            model.beta_d = args.min_beta + frac * (args.max_beta - args.min_beta)
            model.beta_x = args.min_beta + frac * (args.max_beta - args.min_beta)
            model.beta_y = args.min_beta + frac * (args.max_beta - args.min_beta)
        else:
            model.beta_d = args.max_beta
            model.beta_x = args.max_beta
            model.beta_y = args.max_beta

        train_loss, class_y_loss = train_one_epoch(train_loader, model, optimizer, device)
        acc_d, acc_y = evaluate(train_loader, model, device)
        print(f"Epoch {epoch}: train_loss={train_loss:.4f}, class_y_loss={class_y_loss:.4f}, acc_y={acc_y:.4f}")

        if acc_y > best_y_acc or (acc_y == best_y_acc and class_y_loss < best_loss):
            best_y_acc = acc_y
            best_loss = class_y_loss
            early_counter = 0
            torch.save(model.state_dict(), model_name)
            print(f"âœ… New best model saved with acc_y={best_y_acc:.4f}")
        else:
            early_counter += 1
            if early_counter >= args.early_stop_patience:
                print(f"â± Early stopping triggered at epoch {epoch}")
                break

    # ------------------------------ EvaluaciÃ³n cross-subject ------------------------------ #
    model.load_state_dict(torch.load(model_name, map_location=device))
    test_acc_d, test_acc_y = evaluate(test_loader, model, device)
    print(f"\nğŸ Cross-subject test accuracy - y: {test_acc_y:.4f}, d: {test_acc_d:.4f}")

# ------------------------------ Argparse ------------------------------ #
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--no-cuda', action='store_true', default=False)
    parser.add_argument('--seed', type=int, default=0)
    parser.add_argument('--batch-size', type=int, default=256)
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--lr', type=float, default=0.01)
    parser.add_argument('--outpath', type=str, default='./saved_model')
    parser.add_argument('--d-dim', type=int, default=TRAIN_SUBJECTS)
    parser.add_argument('--x-dim', type=int, default=416)
    parser.add_argument('--y-dim', type=int, default=TOTAL_GESTURES)
    parser.add_argument('--zd-dim', type=int, default=128)
    parser.add_argument('--zx-dim', type=int, default=128)
    parser.add_argument('--zy-dim', type=int, default=128)
    parser.add_argument('--aux_loss_multiplier_y', type=float, default=3500.)
    parser.add_argument('--aux_loss_multiplier_d', type=float, default=2000.)
    parser.add_argument('--beta_d', type=float, default=1.)
    parser.add_argument('--beta_x', type=float, default=1.)
    parser.add_argument('--beta_y', type=float, default=1.)
    parser.add_argument('--warmup', type=int, default=100)
    parser.add_argument('--min_beta', type=float, default=0.0)
    parser.add_argument('--max_beta', type=float, default=3.0)
    parser.add_argument('--early_stop_patience', type=int, default=10)
    args = parser.parse_args()
    os.makedirs(args.outpath, exist_ok=True)
    main(args)
